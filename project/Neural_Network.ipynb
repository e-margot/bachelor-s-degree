{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e-margot/bachelor-s-degree/blob/main/FINISH_VERSION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZhfYCduvGpR"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImSWb7t4WXEj"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "import os.path\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor, PILToTensor, ConvertImageDtype, Compose\n",
        "from typing import Any, Callable, Optional, Tuple, List\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dset\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, PILToTensor\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import json\n",
        "import time\n",
        "from matplotlib.collections import PatchCollection\n",
        "from matplotlib.patches import Polygon\n",
        "import copy\n",
        "import itertools\n",
        "import pycocotools._mask as maskUtils\n",
        "from collections import defaultdict\n",
        "import sys\n",
        "PYTHON_VERSION = sys.version_info[0]\n",
        "if PYTHON_VERSION == 2:\n",
        "    from urllib import urlretrieve\n",
        "elif PYTHON_VERSION == 3:\n",
        "    from urllib.request import urlretrieve\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RPcoIQXWsOy",
        "outputId": "6ee12bee-2e37-48ce-f030-684d73b550bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5R6VRrTvVg6"
      },
      "source": [
        "# Overriding COCO and CocoDetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ROtudVSWvqn"
      },
      "outputs": [],
      "source": [
        "def _isArrayLike(obj):\n",
        "    return hasattr(obj, '__iter__') and hasattr(obj, '__len__')\n",
        "\n",
        "\n",
        "class my_COCO:\n",
        "    def __init__(self, annotation_file=None):\n",
        "        \"\"\"\n",
        "        Constructor of Microsoft COCO helper class for reading and visualizing annotations.\n",
        "        :param annotation_file (str): location of annotation file\n",
        "        :param image_folder (str): location to the folder that hosts images.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # load dataset\n",
        "        self.dataset,self.anns,self.cats,self.imgs = dict(),dict(),dict(),dict()\n",
        "        self.imgToAnns, self.catToImgs = defaultdict(list), defaultdict(list)\n",
        "        if not annotation_file == None:\n",
        "            print('loading annotations into memory...')\n",
        "            tic = time.time()\n",
        "            dataset = json.load(open(annotation_file, 'r'))\n",
        "            assert type(dataset)==dict, 'annotation file format {} not supported'.format(type(dataset))\n",
        "            print('Done (t={:0.2f}s)'.format(time.time()- tic))\n",
        "            self.dataset = dataset\n",
        "            self.createIndex()\n",
        "\n",
        "    def createIndex(self):\n",
        "        # create index\n",
        "        print('creating index...')\n",
        "        anns, cats, imgs = {}, {}, {}\n",
        "        imgToAnns,catToImgs = defaultdict(list),defaultdict(list)\n",
        "        if 'annotations' in self.dataset:\n",
        "            for ann in self.dataset['annotations']:\n",
        "                imgToAnns[ann['id']].append(ann)\n",
        "                anns[ann['id']] = ann\n",
        "                imgs[ann['id']] = ann\n",
        "\n",
        "        if 'categories' in self.dataset:\n",
        "            for cat in self.dataset['categories']:\n",
        "                cats[cat['id']] = cat\n",
        "\n",
        "        if 'annotations' in self.dataset and 'categories' in self.dataset:\n",
        "            for ann in self.dataset['annotations']:\n",
        "                catToImgs[ann['category_id']].append(ann['id'])\n",
        "\n",
        "        print('index created!')\n",
        "\n",
        "        # create class members\n",
        "        self.anns = anns\n",
        "        self.imgToAnns = imgToAnns\n",
        "        self.catToImgs = catToImgs\n",
        "        self.imgs = imgs\n",
        "        self.cats = cats\n",
        "\n",
        "    def getAnnIds(self, imgIds=[], catIds=[], areaRng=[], iscrowd=None):\n",
        "        \"\"\"\n",
        "        Get ann ids that satisfy given filter conditions. default skips that filter\n",
        "        :param imgIds  (int array)     : get anns for given imgs\n",
        "               catIds  (int array)     : get anns for given cats\n",
        "               areaRng (float array)   : get anns for given area range (e.g. [0 inf])\n",
        "               iscrowd (boolean)       : get anns for given crowd label (False or True)\n",
        "        :return: ids (int array)       : integer array of ann ids\n",
        "        \"\"\"\n",
        "        imgIds = imgIds if _isArrayLike(imgIds) else [imgIds]\n",
        "        catIds = catIds if _isArrayLike(catIds) else [catIds]\n",
        "\n",
        "        if len(imgIds) == len(catIds) == 0:\n",
        "            anns = self.dataset['annotations']\n",
        "        else:\n",
        "            if not len(imgIds) == 0:\n",
        "                lists = [self.imgToAnns[imgId] for imgId in imgIds if imgId in self.imgToAnns]\n",
        "                anns = list(itertools.chain.from_iterable(lists))\n",
        "            else:\n",
        "                anns = self.dataset['annotations']\n",
        "            anns = anns if len(catIds)  == 0 else [ann for ann in anns if ann['category_id'] in catIds]\n",
        "        if not iscrowd == None:\n",
        "            ids = [ann['id'] for ann in anns if ann['iscrowd'] == iscrowd]\n",
        "        else:\n",
        "            ids = [ann['id'] for ann in anns]\n",
        "        return ids\n",
        "\n",
        "    def getCatIds(self, catNms=[], supNms=[], catIds=[]):\n",
        "        \"\"\"\n",
        "        filtering parameters. default skips that filter.\n",
        "        :param catNms (str array)  : get cats for given cat names\n",
        "        :param supNms (str array)  : get cats for given supercategory names\n",
        "        :param catIds (int array)  : get cats for given cat ids\n",
        "        :return: ids (int array)   : integer array of cat ids\n",
        "        \"\"\"\n",
        "        catNms = catNms if _isArrayLike(catNms) else [catNms]\n",
        "        catIds = catIds if _isArrayLike(catIds) else [catIds]\n",
        "\n",
        "        if len(catNms) == len(catIds) == 0:\n",
        "            cats = self.dataset['categories']\n",
        "        else:\n",
        "            cats = self.dataset['categories']\n",
        "            cats = cats if len(catNms) == 0 else [cat for cat in cats if cat['name']          in catNms]\n",
        "            cats = cats if len(catIds) == 0 else [cat for cat in cats if cat['id']            in catIds]\n",
        "        ids = [cat['id'] for cat in cats]\n",
        "        return ids\n",
        "\n",
        "    def getImgIds(self, imgIds=[], catIds=[]):\n",
        "        '''\n",
        "        Get img ids that satisfy given filter conditions.\n",
        "        :param imgIds (int array) : get imgs for given ids\n",
        "        :param catIds (int array) : get imgs with all given cats\n",
        "        :return: ids (int array)  : integer array of img ids\n",
        "        '''\n",
        "        imgIds = imgIds if _isArrayLike(imgIds) else [imgIds]\n",
        "        catIds = catIds if _isArrayLike(catIds) else [catIds]\n",
        "\n",
        "        if len(imgIds) == len(catIds) == 0:\n",
        "            ids = self.imgs.keys()\n",
        "        else:\n",
        "            ids = set(imgIds)\n",
        "            for i, catId in enumerate(catIds):\n",
        "                if i == 0 and len(ids) == 0:\n",
        "                    ids = set(self.catToImgs[catId])\n",
        "                else:\n",
        "                    ids &= set(self.catToImgs[catId])\n",
        "        return list(ids)\n",
        "\n",
        "    def cls(self, ids=[]):\n",
        "        target = [0] * 80\n",
        "        a = ([self.anns[id]['category_id'] for id in ids])\n",
        "        target[a[0] - 1] = 1\n",
        "        return target\n",
        "    \n",
        "    def loadAnns(self, ids=[]):\n",
        "        \"\"\"\n",
        "        Load anns with the specified ids.\n",
        "        :param ids (int array)       : integer ids specifying anns\n",
        "        :return: anns (object array) : loaded ann objects\n",
        "        \"\"\"\n",
        "        if _isArrayLike(ids):\n",
        "            return self.cls(ids)\n",
        "        elif type(ids) == int:\n",
        "            return [self.anns[ids]]\n",
        "\n",
        "    def loadCats(self, ids=[]):\n",
        "        \"\"\"\n",
        "        Load cats with the specified ids.\n",
        "        :param ids (int array)       : integer ids specifying cats\n",
        "        :return: cats (object array) : loaded cat objects\n",
        "        \"\"\"\n",
        "        if _isArrayLike(ids):\n",
        "            return [self.cats[id] for id in ids]\n",
        "        elif type(ids) == int:\n",
        "            return [self.cats[ids]]\n",
        "\n",
        "    def loadImgs(self, ids=[]):\n",
        "        \"\"\"\n",
        "        Load anns with the specified ids.\n",
        "        :param ids (int array)       : integer ids specifying img\n",
        "        :return: imgs (object array) : loaded img objects\n",
        "        \"\"\"\n",
        "        if _isArrayLike(ids):\n",
        "            return [self.imgs[id] for id in ids]\n",
        "        elif type(ids) == int:\n",
        "            return [self.imgs[ids]]\n",
        "\n",
        "    def download(self, tarDir = None, imgIds = [] ):\n",
        "        '''\n",
        "        Download COCO images from mscoco.org server.\n",
        "        :param tarDir (str): COCO results directory name\n",
        "               imgIds (list): images to be downloaded\n",
        "        :return:\n",
        "        '''\n",
        "        if tarDir is None:\n",
        "            print('Please specify target directory')\n",
        "            return -1\n",
        "        if len(imgIds) == 0:\n",
        "            imgs = self.imgs.values()\n",
        "        else:\n",
        "            imgs = self.loadImgs(imgIds)\n",
        "        N = len(imgs)\n",
        "        if not os.path.exists(tarDir):\n",
        "            os.makedirs(tarDir)\n",
        "        for i, img in enumerate(imgs):\n",
        "            tic = time.time()\n",
        "            fname = os.path.join(tarDir, img['file_name'])\n",
        "            if not os.path.exists(fname):\n",
        "                urlretrieve(img['coco_url'], fname)\n",
        "            print('downloaded {}/{} images (t={:0.1f}s)'.format(i, N, time.time()- tic))\n",
        "\n",
        "    def loadNumpyAnnotations(self, data):\n",
        "        \"\"\"\n",
        "        Convert result data from a numpy array [Nx7] where each row contains {imageID,x1,y1,w,h,score,class}\n",
        "        :param  data (numpy.ndarray)\n",
        "        :return: annotations (python nested list)\n",
        "        \"\"\"\n",
        "        print('Converting ndarray to lists...')\n",
        "        assert(type(data) == np.ndarray)\n",
        "        print(data.shape)\n",
        "        assert(data.shape[1] == 7)\n",
        "        N = data.shape[0]\n",
        "        ann = []\n",
        "        for i in range(N):\n",
        "            if i % 1000000 == 0:\n",
        "                print('{}/{}'.format(i,N))\n",
        "            ann += [{\n",
        "                'image_id'  : int(data[i, 0]),\n",
        "                'bbox'  : [ data[i, 1], data[i, 2], data[i, 3], data[i, 4] ],\n",
        "                'score' : data[i, 5],\n",
        "                'category_id': int(data[i, 6]),\n",
        "                }]\n",
        "        return ann\n",
        "\n",
        "    def annToRLE(self, ann):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        t = self.imgs[ann['image_id']]\n",
        "        h, w = t['height'], t['width']\n",
        "        segm = ann['segmentation']\n",
        "        if type(segm) == list:\n",
        "            # polygon -- a single object might consist of multiple parts\n",
        "            # we merge all parts into one mask rle code\n",
        "            rles = maskUtils.frPyObjects(segm, h, w)\n",
        "            rle = maskUtils.merge(rles)\n",
        "        elif type(segm['counts']) == list:\n",
        "            # uncompressed RLE\n",
        "            rle = maskUtils.frPyObjects(segm, h, w)\n",
        "        else:\n",
        "            # rle\n",
        "            rle = ann['segmentation']\n",
        "        return rle\n",
        "\n",
        "    def annToMask(self, ann):\n",
        "        \"\"\"\n",
        "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
        "        :return: binary mask (numpy 2D array)\n",
        "        \"\"\"\n",
        "        rle = self.annToRLE(ann)\n",
        "        m = maskUtils.decode(rle)\n",
        "        return m\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Wv5O49TW0ls"
      },
      "outputs": [],
      "source": [
        "class my_CocoDetection(VisionDataset):\n",
        "    \"\"\"`MS Coco Detection <https://cocodataset.org/#detection-2016>`_ Dataset.\n",
        "\n",
        "    It requires the `COCO API to be installed <https://github.com/pdollar/coco/tree/master/PythonAPI>`_.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory where images are downloaded to.\n",
        "        annFile (string): Path to json annotation file.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.ToTensor``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
        "            and returns a transformed version.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        annFile: str,\n",
        "        transform: Optional[Callable] = None,\n",
        "        target_transform: Optional[Callable] = None,\n",
        "        transforms: Optional[Callable] = None,\n",
        "    ) -> None:\n",
        "        super().__init__(root, transforms, transform, target_transform)\n",
        "        from pycocotools.coco import COCO\n",
        "\n",
        "        self.coco = my_COCO(annFile)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def _load_image(self, id: int) -> Image.Image:\n",
        "        path = self.coco.loadImgs(id)[0][\"file_name\"]\n",
        "        return Image.open(os.path.join(self.root, os.path.basename(path))).convert('L').resize((256, 256))\n",
        "\n",
        "    def _load_target(self, id: int):\n",
        "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        id = self.ids[index]\n",
        "        image = self._load_image(id)\n",
        "        target = torch.as_tensor(self._load_target(id), dtype = torch.float32)\n",
        "        if self.transforms is not None:\n",
        "            image, target = self.transforms(image, target)\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.ids)\n",
        "    \n",
        "    def printf(self):\n",
        "      print(self.root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF5BT_zTvf9O"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-958ecjXgj0"
      },
      "outputs": [],
      "source": [
        "transform = Compose([PILToTensor(), ConvertImageDtype(torch.float)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqbrdRU9XvKo"
      },
      "outputs": [],
      "source": [
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egoaGzghy30R"
      },
      "source": [
        "TV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Feo4iiVJXjKn"
      },
      "outputs": [],
      "source": [
        "path2data = \"/content/drive/MyDrive/FLIR_ADAS_v2/FLIR_ADAS_v2/images_thermal_train/new_data\"\n",
        "path2json = \"/content/drive/MyDrive/FLIR_ADAS_v2/FLIR_ADAS_v2/images_thermal_train/ann.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UnoR8PbXkVq",
        "outputId": "fee9bc72-313f-447a-bfb1-dc30cc9fc56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "coco_TV = my_CocoDetection(path2data, path2json, transform = transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_BbLVlvX0Vl"
      },
      "outputs": [],
      "source": [
        "coco_loader_TV = DataLoader(coco_TV, batch_size, shuffle=True, num_workers = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSoTM8mPy5Rb"
      },
      "source": [
        "NIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1FnT3sO0SKB"
      },
      "outputs": [],
      "source": [
        "path2data = \"/content/drive/MyDrive/FLIR_ADAS_v2/FLIR_ADAS_v2/images_thermal_val/new_data\"\n",
        "path2json = \"/content/drive/MyDrive/FLIR_ADAS_v2/FLIR_ADAS_v2/images_thermal_val/ann.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc8Pz3Fm0VXh",
        "outputId": "937cdb8e-5fe4-4b38-fe1a-09e777a37115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.04s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "coco_NIR = my_CocoDetection(path2data, path2json, transform = transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQak2hmx0Y6S"
      },
      "outputs": [],
      "source": [
        "coco_loader_NIR = DataLoader(coco_NIR, batch_size, shuffle=True, num_workers = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GM4mmzvoDC"
      },
      "source": [
        "# Override Resnet34\n",
        "https://www.kaggle.com/code/poonaml/building-resnet34-from-scratch-using-pytorch/notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgBi_2Ugvuzd"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                     padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoRPjv-aDD8A"
      },
      "outputs": [],
      "source": [
        "def _make_layer(block, inplanes,planes, blocks, stride=1):\n",
        "    downsample = None  \n",
        "    if stride != 1 or inplanes != planes:\n",
        "        downsample = nn.Sequential(            \n",
        "            nn.Conv2d(inplanes, planes, 1, stride, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "        )\n",
        "    layers = []\n",
        "    layers.append(block(inplanes, planes, stride, downsample))\n",
        "    inplanes = planes\n",
        "    for _ in range(1, blocks):\n",
        "        layers.append(block(inplanes, planes))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbdZQXmGDGfI"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=80):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.inplanes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 , num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None  \n",
        "   \n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes, 1, stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        \n",
        "        self.inplanes = planes\n",
        "        \n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)           # 224x224\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)         # 112x112\n",
        "\n",
        "        x = self.layer1(x)          # 56x56\n",
        "        x = self.layer2(x)          # 28x28\n",
        "        x = self.layer3(x)          # 14x14\n",
        "        x = self.layer4(x)          # 7x7\n",
        "\n",
        "        x = self.avgpool(x)         # 1x1\n",
        "        x = torch.flatten(x, 1)     # remove 1 X 1 grid and make vector of tensor shape \n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL5rdjUQDSkl"
      },
      "outputs": [],
      "source": [
        "def resnet34():\n",
        "    layers=[3, 4, 6, 3]\n",
        "    model = ResNet(BasicBlock, layers)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOkCmDuKX2w9"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3kUd2wqX5KN",
        "outputId": "b3fe46c6-4fda-4345-c2fe-d2f0076bf1ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaabE73DYFl4"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    # _, preds = torch.max(outputs, dim=1)\n",
        "    # return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    _, targs = torch.max(labels, dim=1)\n",
        "    # print(preds)\n",
        "    # print(targs)\n",
        "    return torch.tensor(torch.sum(preds == targs).item() / len(preds))\n",
        "\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        labels1 = labels.softmax(dim=1)\n",
        "        loss = F.cross_entropy(out, labels1)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "      \n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6iLyKhGEhMd"
      },
      "outputs": [],
      "source": [
        "coco_loader_NIR = DeviceDataLoader(coco_loader_NIR, device)\n",
        "coco_loader_TV = DeviceDataLoader(coco_loader_TV, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjhVga9VwU9K",
        "outputId": "ec985f69-8587-4901-fadf-24d9d1f66c98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "resnet34_debug = resnet34()\n",
        "resnet34_debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVsZHU-KYL6u",
        "outputId": "e5e2733e-f034-44c8-a051-fd0ef8f13481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FLIR80Resnet(\n",
              "  (network): ResNet(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (5): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=80, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "class FLIR80Resnet(ImageClassificationBase):\n",
        "        def __init__(self):\n",
        "                super().__init__()\n",
        "                self.network = resnet34()\n",
        "                num_ftrs = self.network.fc.in_features\n",
        "                self.network.fc = nn.Linear(num_ftrs, 80)\n",
        "        \n",
        "        def forward(self, xb):\n",
        "                return self.network(xb)\n",
        "            \n",
        "model = FLIR80Resnet()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc4avqv1YPtz"
      },
      "outputs": [],
      "source": [
        "model = to_device(FLIR80Resnet(), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efgYtWwuYZy2"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    # outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    outputs2 = []\n",
        "    i = 0\n",
        "    for batch in val_loader:\n",
        "      print(i)\n",
        "      i+=1\n",
        "      outputs2.append(model.validation_step(batch))\n",
        "    return model.validation_epoch_end(outputs2)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, \n",
        "        weight_decay=0, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr, weight_decay=weight_decay)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ET-51LOYcEy"
      },
      "outputs": [],
      "source": [
        "history = [evaluate(model, coco_loader_TV)]\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG75cDYfweh1"
      },
      "outputs": [],
      "source": [
        "# For this model we gonna use Adam Optimization\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVHyxmUr043O"
      },
      "outputs": [],
      "source": [
        "train_dl = coco_loader_TV\n",
        "valid_dl = coco_loader_NIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3NJDALWyTAs"
      },
      "outputs": [],
      "source": [
        "history = fit(8, 1e-3, model, train_dl, valid_dl, 5e-4, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npswlXPhyWFY"
      },
      "outputs": [],
      "source": [
        "history = fit(10, 1e-5, model, train_dl, valid_dl, 5e-4, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjogrfdFyYRU"
      },
      "outputs": [],
      "source": [
        "# history = fit(5, 1e-4, model, train_dl, valid_dl, 5e-4, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAA5iNB3yY-L"
      },
      "outputs": [],
      "source": [
        "# history = fit(15, 1e-4, model, train_dl, valid_dl, 5e-4, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4DZWRsHyarI"
      },
      "outputs": [],
      "source": [
        "# history = fit(25, 1e-5, model, train_dl, valid_dl, 5e-4, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs')\n",
        "    fname = 'accuracy.jpg'\n",
        "    plt.savefig(fname)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XEPLCyERsj4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)"
      ],
      "metadata": {
        "id": "6ScjuCZIss8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    # plt.plot(train_losses, '-bx')\n",
        "    # plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    # plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs')\n",
        "    fname = 'loss_func.jpg'\n",
        "    plt.savefig(fname)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Gwdzk05lsuKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "DPkyWvTyszT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FINISH VERSION",
      "provenance": [],
      "authorship_tag": "ABX9TyPy19xQ4pW5YQVrLVUEni/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
